"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[9386],{8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var i=t(6540);const s={},a=i.createContext(s);function o(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(a.Provider,{value:n},e.children)}},9610:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-1/python-ros2-integration-rclpy/lesson-4.3-complete-system-integration","title":"Lesson 4.3 - Complete System Integration","description":"Learning Objectives","source":"@site/docs/module-1/4-python-ros2-integration-rclpy/lesson-4.3-complete-system-integration.md","sourceDirName":"module-1/4-python-ros2-integration-rclpy","slug":"/module-1/python-ros2-integration-rclpy/lesson-4.3-complete-system-integration","permalink":"/Physical_AI_Humanoid_Robotics_Book_With_RAG_Chatbot/docs/module-1/python-ros2-integration-rclpy/lesson-4.3-complete-system-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/AmanNazim/Physical_AI_Humanoid_Robotics_Book_With_RAG_Chatbot/edit/main/physical-ai-humanoid-robotics-book/docs/module-1/4-python-ros2-integration-rclpy/lesson-4.3-complete-system-integration.md","tags":[],"version":"current","frontMatter":{"title":"Lesson 4.3 - Complete System Integration"},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 4.2 - Simulation Environment Setup","permalink":"/Physical_AI_Humanoid_Robotics_Book_With_RAG_Chatbot/docs/module-1/python-ros2-integration-rclpy/lesson-4.2-simulation-environment-setup"},"next":{"title":"Module 2 - The Digital Twin (Gazebo & Unity)","permalink":"/Physical_AI_Humanoid_Robotics_Book_With_RAG_Chatbot/docs/module-2/introduction"}}');var s=t(4848),a=t(8453);const o={title:"Lesson 4.3 - Complete System Integration"},r="Lesson 4.3 \u2013 Complete System Integration",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Concept Overview and Scope",id:"concept-overview-and-scope",level:2},{value:"Complete Perception-to-Action Pipeline Implementation",id:"complete-perception-to-action-pipeline-implementation",level:2},{value:"1. Complete Pipeline Architecture",id:"1-complete-pipeline-architecture",level:3},{value:"End-to-End System Validation",id:"end-to-end-system-validation",level:2},{value:"1. Validation Framework",id:"1-validation-framework",level:3},{value:"Hardware Abstraction Layer Implementation",id:"hardware-abstraction-layer-implementation",level:2},{value:"1. Hardware Interface Abstraction",id:"1-hardware-interface-abstraction",level:3},{value:"Time Synchronization Implementation",id:"time-synchronization-implementation",level:2},{value:"1. Time Synchronization Node",id:"1-time-synchronization-node",level:3},{value:"Complete Integration Launch File",id:"complete-integration-launch-file",level:2},{value:"Python Launch File",id:"python-launch-file",level:3},{value:"Validation and Testing Procedures",id:"validation-and-testing-procedures",level:2},{value:"1. Automated Validation Tests",id:"1-automated-validation-tests",level:3},{value:"Step-by-Step Integration Exercise",id:"step-by-step-integration-exercise",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"lesson-43--complete-system-integration",children:"Lesson 4.3 \u2013 Complete System Integration"})}),"\n",(0,s.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Implement complete perception-to-action pipelines for elementary tasks"}),"\n",(0,s.jsx)(n.li,{children:"Perform end-to-end system validation"}),"\n",(0,s.jsx)(n.li,{children:"Create complete integrated systems with validation tests"}),"\n",(0,s.jsx)(n.li,{children:"Validate simulation compatibility with real hardware interfaces"}),"\n",(0,s.jsx)(n.li,{children:"Implement time synchronization between real and simulation time"}),"\n",(0,s.jsx)(n.li,{children:"Create hardware abstraction layers for simulation compatibility"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"concept-overview-and-scope",children:"Concept Overview and Scope"}),"\n",(0,s.jsx)(n.p,{children:"This lesson focuses on integrating all components developed in previous chapters into a complete, functioning system. We'll implement complete perception-to-action pipelines, validate the entire system, and ensure compatibility between simulation and real hardware. This represents the culmination of Module 1, where we connect the communication infrastructure, robot description, Python AI agents, and simulation environment into a unified system."}),"\n",(0,s.jsx)(n.h2,{id:"complete-perception-to-action-pipeline-implementation",children:"Complete Perception-to-Action Pipeline Implementation"}),"\n",(0,s.jsx)(n.p,{children:"In this section, we'll implement a complete perception-to-action pipeline that integrates all the components we've developed:"}),"\n",(0,s.jsx)(n.h3,{id:"1-complete-pipeline-architecture",children:"1. Complete Pipeline Architecture"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Image, JointState, Imu\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import String, Float64MultiArray\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\nimport math\nfrom collections import deque\n\nclass CompletePerceptionActionPipeline(Node):\n    def __init__(self):\n        super().__init__(\'complete_perception_action_pipeline\')\n\n        # Subscriptions for all sensor modalities\n        self.laser_sub = self.create_subscription(\n            LaserScan, \'/scan\', self.laser_callback, 10)\n        self.camera_sub = self.create_subscription(\n            Image, \'/camera/image_raw\', self.camera_callback, 10)\n        self.joint_sub = self.create_subscription(\n            JointState, \'/joint_states\', self.joint_callback, 10)\n        self.imu_sub = self.create_subscription(\n            Imu, \'/imu/data\', self.imu_callback, 10)\n\n        # Publishers for all action modalities\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.joint_cmd_pub = self.create_publisher(Float64MultiArray, \'/position_controller/commands\', 10)\n        self.status_pub = self.create_publisher(String, \'/system_status\', 10)\n\n        # CV Bridge for image processing\n        self.cv_bridge = CvBridge()\n\n        # State variables and buffers\n        self.laser_buffer = deque(maxlen=5)  # Store last 5 laser scans\n        self.image_buffer = deque(maxlen=3)  # Store last 3 images\n        self.joint_buffer = deque(maxlen=10)  # Store last 10 joint states\n        self.imu_buffer = deque(maxlen=10)   # Store last 10 IMU readings\n\n        # System state\n        self.current_behavior = "IDLE"\n        self.system_health = {"sensors": True, "controllers": True, "communication": True}\n        self.last_sensor_update = self.get_clock().now()\n\n        # Pipeline processing timer (20Hz)\n        self.pipeline_timer = self.create_timer(0.05, self.pipeline_loop)\n\n        # Health monitoring timer (1Hz)\n        self.health_timer = self.create_timer(1.0, self.health_check)\n\n        self.get_logger().info(\'Complete Perception-to-Action Pipeline has been initialized\')\n\n    def laser_callback(self, msg):\n        self.laser_buffer.append(msg)\n        self.last_sensor_update = self.get_clock().now()\n\n    def camera_callback(self, msg):\n        try:\n            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, "bgr8")\n            self.image_buffer.append(cv_image)\n        except Exception as e:\n            self.get_logger().error(f\'Error converting image: {e}\')\n\n    def joint_callback(self, msg):\n        self.joint_buffer.append(msg)\n\n    def imu_callback(self, msg):\n        self.imu_buffer.append(msg)\n\n    def pipeline_loop(self):\n        """Main pipeline processing loop"""\n        # Check if we have recent sensor data\n        time_since_update = self.get_clock().now() - self.last_sensor_update\n        if time_since_update.nanoseconds / 1e9 > 2.0:  # No data for 2 seconds\n            self.current_behavior = "NO_SENSOR_DATA"\n            self.system_health["sensors"] = False\n            self.publish_status(f"ERROR: No sensor data for {time_since_update.nanoseconds / 1e9:.1f}s")\n            return\n\n        self.system_health["sensors"] = True\n\n        # Process sensor data and make decisions\n        action_command = self.process_sensors_and_decide()\n\n        # Execute action\n        self.execute_action(action_command)\n\n        # Publish system status\n        self.publish_status(f"BEHAVIOR: {self.current_behavior} | HEALTH: {self.system_health}")\n\n    def process_sensors_and_decide(self):\n        """Process all sensor data and decide on action"""\n        # Get latest sensor data\n        latest_laser = self.laser_buffer[-1] if self.laser_buffer else None\n        latest_image = self.image_buffer[-1] if self.image_buffer else None\n        latest_joints = self.joint_buffer[-1] if self.joint_buffer else None\n        latest_imu = self.imu_buffer[-1] if self.imu_buffer else None\n\n        # Initialize command\n        command = {\n            "cmd_vel": Twist(),\n            "joint_cmd": Float64MultiArray(),\n            "behavior": "IDLE"\n        }\n\n        if latest_laser is None:\n            return command\n\n        # Multi-sensor fusion for decision making\n        # 1. Obstacle detection from laser\n        obstacles_detected = self.analyze_obstacles(latest_laser)\n\n        # 2. Visual processing\n        visual_features = self.analyze_visual_data(latest_image) if latest_image is not None else {}\n\n        # 3. Joint state analysis\n        joint_analysis = self.analyze_joints(latest_joints) if latest_joints is not None else {}\n\n        # 4. IMU analysis\n        imu_analysis = self.analyze_imu(latest_imu) if latest_imu is not None else {}\n\n        # Decision logic based on all sensor inputs\n        if obstacles_detected["front"] < 0.5:\n            # Emergency stop for close obstacles\n            command["cmd_vel"].linear.x = 0.0\n            command["cmd_vel"].angular.z = 0.0\n            command["behavior"] = "EMERGENCY_STOP"\n        elif "red_object" in visual_features and visual_features["red_object"]["distance"] < 2.0:\n            # Approach red object\n            command["cmd_vel"].linear.x = 0.3\n            command["cmd_vel"].angular.z = visual_features["red_object"]["angular_correction"]\n            command["behavior"] = "APPROACH_RED_OBJECT"\n        elif obstacles_detected["front"] < 1.0:\n            # Avoid obstacles\n            command["cmd_vel"].linear.x = 0.0\n            if obstacles_detected["left"] > obstacles_detected["right"]:\n                command["cmd_vel"].angular.z = 0.5  # Turn left\n            else:\n                command["cmd_vel"].angular.z = -0.5  # Turn right\n            command["behavior"] = "AVOIDING_OBSTACLE"\n        else:\n            # Normal exploration\n            command["cmd_vel"].linear.x = 0.5\n            command["cmd_vel"].angular.z = 0.0\n            command["behavior"] = "EXPLORING"\n\n        self.current_behavior = command["behavior"]\n        return command\n\n    def analyze_obstacles(self, laser_msg):\n        """Analyze laser scan for obstacles"""\n        ranges = laser_msg.ranges\n        n = len(ranges)\n\n        # Divide scan into sectors\n        front_ranges = ranges[:n//8] + ranges[-n//8:]\n        left_ranges = ranges[n*3//8:n*5//8]\n        right_ranges = ranges[n*5//8:n*7//8]\n\n        # Calculate minimum distances in each sector\n        front_min = min(front_ranges) if front_ranges else float(\'inf\')\n        left_min = min(left_ranges) if left_ranges else float(\'inf\')\n        right_min = min(right_ranges) if right_ranges else float(\'inf\')\n\n        return {\n            "front": front_min,\n            "left": left_min,\n            "right": right_min\n        }\n\n    def analyze_visual_data(self, image):\n        """Analyze visual data for features"""\n        if image is None:\n            return {}\n\n        features = {}\n\n        # Look for red objects\n        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        red_mask = cv2.inRange(hsv, (0, 100, 100), (10, 255, 255))\n        red_mask = cv2.inRange(hsv, (170, 100, 100), (180, 255, 255)) | red_mask\n\n        # Find contours of red objects\n        contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        if contours:\n            # Find largest red contour\n            largest_contour = max(contours, key=cv2.contourArea)\n            if cv2.contourArea(largest_contour) > 500:  # Only consider significant objects\n                # Calculate center of the object\n                M = cv2.moments(largest_contour)\n                if M["m00"] != 0:\n                    cx = int(M["m10"] / M["m00"])\n                    cy = int(M["m01"] / M["m00"])\n\n                    # Calculate angular correction needed to center the object\n                    img_center_x = image.shape[1] / 2\n                    angular_correction = (cx - img_center_x) / img_center_x * 0.5  # Scale to reasonable range\n\n                    features["red_object"] = {\n                        "distance": 1.0,  # Placeholder - would use depth in real system\n                        "angular_correction": angular_correction\n                    }\n\n        return features\n\n    def analyze_joints(self, joint_msg):\n        """Analyze joint states"""\n        if joint_msg is None:\n            return {}\n\n        analysis = {\n            "positions": list(joint_msg.position),\n            "velocities": list(joint_msg.velocity),\n            "efforts": list(joint_msg.effort)\n        }\n\n        return analysis\n\n    def analyze_imu(self, imu_msg):\n        """Analyze IMU data"""\n        if imu_msg is None:\n            return {}\n\n        analysis = {\n            "orientation": {\n                "x": imu_msg.orientation.x,\n                "y": imu_msg.orientation.y,\n                "z": imu_msg.orientation.z,\n                "w": imu_msg.orientation.w\n            },\n            "angular_velocity": {\n                "x": imu_msg.angular_velocity.x,\n                "y": imu_msg.angular_velocity.y,\n                "z": imu_msg.angular_velocity.z\n            },\n            "linear_acceleration": {\n                "x": imu_msg.linear_acceleration.x,\n                "y": imu_msg.linear_acceleration.y,\n                "z": imu_msg.linear_acceleration.z\n            }\n        }\n\n        return analysis\n\n    def execute_action(self, command):\n        """Execute the decided action"""\n        # Publish velocity command\n        self.cmd_vel_pub.publish(command["cmd_vel"])\n\n        # Publish joint commands if needed\n        if command["joint_cmd"].data:\n            self.joint_cmd_pub.publish(command["joint_cmd"])\n\n    def publish_status(self, status_msg):\n        """Publish system status"""\n        msg = String()\n        msg.data = status_msg\n        self.status_pub.publish(msg)\n\n    def health_check(self):\n        """Perform system health check"""\n        # Check if we have recent joint data\n        if self.joint_buffer:\n            latest_joint_time = self.get_clock().now()  # In a real system, we\'d check the actual timestamp\n            # This is a simplified check - in practice, we\'d verify communication with real joints\n            self.system_health["controllers"] = True\n\n        # Check communication health\n        self.system_health["communication"] = True  # Simplified check\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = CompletePerceptionActionPipeline()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info(\'Shutting down complete pipeline...\')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"end-to-end-system-validation",children:"End-to-End System Validation"}),"\n",(0,s.jsx)(n.p,{children:"In this section, we'll implement comprehensive validation techniques for our integrated system:"}),"\n",(0,s.jsx)(n.h3,{id:"1-validation-framework",children:"1. Validation Framework"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import String\nfrom builtin_interfaces.msg import Time\nimport time\nimport json\n\nclass SystemValidator(Node):\n    def __init__(self):\n        super().__init__(\'system_validator\')\n\n        # Subscriptions for monitoring system behavior\n        self.joint_sub = self.create_subscription(JointState, \'/joint_states\', self.joint_callback, 10)\n        self.cmd_sub = self.create_subscription(Twist, \'/cmd_vel\', self.cmd_callback, 10)\n        self.status_sub = self.create_subscription(String, \'/system_status\', self.status_callback, 10)\n\n        # Validation parameters\n        self.validation_results = {\n            "sensor_data_validity": True,\n            "control_response_time": 0.0,\n            "communication_stability": True,\n            "behavior_consistency": True\n        }\n\n        # Validation timer (check every 5 seconds)\n        self.validation_timer = self.create_timer(5.0, self.run_validation)\n\n        # Performance monitoring\n        self.cmd_timestamps = []\n        self.joint_timestamps = []\n\n        self.get_logger().info(\'System Validator has been initialized\')\n\n    def joint_callback(self, msg):\n        # Record joint state timestamp for performance analysis\n        self.joint_timestamps.append(self.get_clock().now())\n\n    def cmd_callback(self, msg):\n        # Record command timestamp for response time analysis\n        self.cmd_timestamps.append(self.get_clock().now())\n\n    def status_callback(self, msg):\n        # Monitor system status for behavioral consistency\n        if "ERROR" in msg.data:\n            self.validation_results["behavior_consistency"] = False\n\n    def run_validation(self):\n        """Run comprehensive system validation"""\n        self.get_logger().info(\'Starting system validation...\')\n\n        # 1. Sensor data validity check\n        self.check_sensor_validity()\n\n        # 2. Control response time check\n        self.check_control_response_time()\n\n        # 3. Communication stability check\n        self.check_communication_stability()\n\n        # 4. Behavior consistency check\n        self.check_behavior_consistency()\n\n        # Report validation results\n        self.report_validation_results()\n\n    def check_sensor_validity(self):\n        """Validate that sensor data is reasonable"""\n        # This is a placeholder - in practice, we\'d check for:\n        # - Data ranges (e.g., joint positions within limits)\n        # - Update frequency (sensors publishing at expected rate)\n        # - Data quality (no NaN or inf values)\n        self.validation_results["sensor_data_validity"] = True\n\n    def check_control_response_time(self):\n        """Check that control commands are responded to in time"""\n        if len(self.cmd_timestamps) > 1 and len(self.joint_timestamps) > 1:\n            # Calculate response time between command and joint movement\n            cmd_time = self.cmd_timestamps[-1]\n            joint_time = self.joint_timestamps[-1]\n\n            response_time = (joint_time.nanoseconds - cmd_time.nanoseconds) / 1e9\n            self.validation_results["control_response_time"] = response_time\n\n            if response_time > 0.5:  # More than 500ms is too slow\n                self.get_logger().warning(f\'Control response time is too slow: {response_time:.3f}s\')\n                self.validation_results["communication_stability"] = False\n\n    def check_communication_stability(self):\n        """Check for communication stability"""\n        # Check if topics are publishing at expected rates\n        # This is a simplified check\n        self.validation_results["communication_stability"] = True\n\n    def check_behavior_consistency(self):\n        """Check that system behaves consistently"""\n        # This would involve more complex behavioral validation\n        # For now, we just ensure no error messages in status\n        pass\n\n    def report_validation_results(self):\n        """Report validation results"""\n        self.get_logger().info(\'--- System Validation Results ---\')\n        for test, result in self.validation_results.items():\n            status = "PASS" if result else "FAIL"\n            self.get_logger().info(f\'{test}: {status}\')\n        self.get_logger().info(\'--- End Validation Results ---\')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    validator = SystemValidator()\n\n    # Run validation for 30 seconds\n    start_time = time.time()\n    end_time = start_time + 30\n\n    try:\n        while time.time() < end_time:\n            rclpy.spin_once(validator, timeout_sec=0.1)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        validator.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"hardware-abstraction-layer-implementation",children:"Hardware Abstraction Layer Implementation"}),"\n",(0,s.jsx)(n.p,{children:"To ensure compatibility between simulation and real hardware, we need to implement hardware abstraction:"}),"\n",(0,s.jsx)(n.h3,{id:"1-hardware-interface-abstraction",children:"1. Hardware Interface Abstraction"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState, Imu\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import Float64MultiArray\nimport threading\nimport time\n\nclass HardwareInterface(Node):\n    def __init__(self, is_simulation=True):\n        super().__init__(\'hardware_interface\')\n\n        self.is_simulation = is_simulation\n        self.hardware_connected = False\n        self.lock = threading.Lock()\n\n        # Publishers and subscribers\n        self.joint_state_pub = self.create_publisher(JointState, \'/joint_states\', 10)\n        self.imu_pub = self.create_publisher(Imu, \'/imu/data\', 10)\n        self.cmd_vel_sub = self.create_subscription(Twist, \'/cmd_vel\', self.cmd_vel_callback, 10)\n        self.joint_cmd_sub = self.create_subscription(Float64MultiArray, \'/joint_commands\', self.joint_cmd_callback, 10)\n\n        # Initialize hardware interface\n        self.initialize_hardware()\n\n    def initialize_hardware(self):\n        """Initialize connection to hardware or simulation"""\n        if self.is_simulation:\n            self.get_logger().info(\'Initializing in simulation mode\')\n            # In simulation, we rely on Gazebo plugins for hardware simulation\n            self.hardware_connected = True\n        else:\n            self.get_logger().info(\'Initializing in real hardware mode\')\n            # Connect to real hardware (simplified example)\n            try:\n                # Connect to actual hardware controller\n                # self.hardware_controller = RealHardwareController()\n                # self.hardware_connected = self.hardware_controller.connect()\n                self.hardware_connected = True  # Placeholder\n                self.get_logger().info(\'Hardware connected successfully\')\n            except Exception as e:\n                self.get_logger().error(f\'Failed to connect to hardware: {e}\')\n                self.hardware_connected = False\n\n    def cmd_vel_callback(self, msg):\n        """Handle velocity commands"""\n        with self.lock:\n            if self.hardware_connected:\n                if self.is_simulation:\n                    # In simulation, commands are handled by Gazebo\n                    # We just validate the command\n                    self.validate_and_publish_cmd_vel(msg)\n                else:\n                    # Send command to real hardware\n                    self.send_cmd_vel_to_hardware(msg)\n\n    def joint_cmd_callback(self, msg):\n        """Handle joint commands"""\n        with self.lock:\n            if self.hardware_connected:\n                if self.is_simulation:\n                    # In simulation, joint commands go through controller manager\n                    self.publish_joint_commands(msg)\n                else:\n                    # Send joint commands to real hardware\n                    self.send_joint_commands_to_hardware(msg)\n\n    def validate_and_publish_cmd_vel(self, cmd_vel):\n        """Validate and publish velocity commands (simulation mode)"""\n        # Apply safety limits\n        max_linear = 1.0  # m/s\n        max_angular = 1.0  # rad/s\n\n        cmd_vel.linear.x = max(min(cmd_vel.linear.x, max_linear), -max_linear)\n        cmd_vel.angular.z = max(min(cmd_vel.angular.z, max_angular), -max_angular)\n\n        # In simulation, the command is handled by the simulation environment\n        # We just validate and potentially log\n        self.get_logger().debug(f\'Validated cmd_vel: linear={cmd_vel.linear.x}, angular={cmd_vel.angular.z}\')\n\n    def send_cmd_vel_to_hardware(self, cmd_vel):\n        """Send velocity commands to real hardware"""\n        # This would send commands to real hardware controller\n        # For example: self.hardware_controller.send_velocity_command(cmd_vel)\n        self.get_logger().info(f\'Sent cmd_vel to hardware: linear={cmd_vel.linear.x}, angular={cmd_vel.angular.z}\')\n\n    def publish_joint_commands(self, joint_cmd):\n        """Publish joint commands (simulation mode)"""\n        # In simulation, commands are sent to controller manager topics\n        # This would be handled by the controller manager\n        self.get_logger().debug(f\'Published joint commands: {len(joint_cmd.data)} joints\')\n\n    def send_joint_commands_to_hardware(self, joint_cmd):\n        """Send joint commands to real hardware"""\n        # Send commands to real hardware controller\n        # For example: self.hardware_controller.send_joint_commands(joint_cmd.data)\n        self.get_logger().info(f\'Sent joint commands to hardware: {len(joint_cmd.data)} joints\')\n\n    def get_sensor_data(self):\n        """Get sensor data from hardware or simulation"""\n        with self.lock:\n            if self.is_simulation:\n                # In simulation, sensor data comes from Gazebo plugins\n                # This is handled by the simulation environment\n                return None\n            else:\n                # Get data from real hardware sensors\n                # For example: return self.hardware_controller.get_sensor_data()\n                return None\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    # Create both simulation and real hardware interfaces for testing\n    sim_interface = HardwareInterface(is_simulation=True)\n\n    try:\n        rclpy.spin(sim_interface)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        sim_interface.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"time-synchronization-implementation",children:"Time Synchronization Implementation"}),"\n",(0,s.jsx)(n.p,{children:"Proper time synchronization is crucial for both simulation and real hardware:"}),"\n",(0,s.jsx)(n.h3,{id:"1-time-synchronization-node",children:"1. Time Synchronization Node"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom builtin_interfaces.msg import Time\nfrom std_msgs.msg import Header\nimport time\n\nclass TimeSynchronizer(Node):\n    def __init__(self):\n        super().__init__('time_synchronizer')\n\n        # Time synchronization parameters\n        self.use_sim_time = self.declare_parameter('use_sim_time', False).value\n        self.time_offset = 0.0  # Offset between real and simulation time\n        self.time_scale = 1.0   # Time scaling factor for simulation\n\n        # Time synchronization publisher\n        self.time_sync_pub = self.create_publisher(Time, '/time_sync', 10)\n\n        # Time sync timer (10Hz)\n        self.sync_timer = self.create_timer(0.1, self.synchronize_time)\n\n        self.get_logger().info(f'Time Synchronizer initialized (use_sim_time: {self.use_sim_time})')\n\n    def synchronize_time(self):\n        \"\"\"Synchronize time between real and simulation environments\"\"\"\n        if self.use_sim_time:\n            # In simulation, use Gazebo's simulation time\n            # This is typically handled automatically by ROS2 parameters\n            sim_time_msg = self.get_clock().now().to_msg()\n            self.time_sync_pub.publish(sim_time_msg)\n        else:\n            # In real hardware, use system time\n            real_time_msg = self.get_clock().now().to_msg()\n            self.time_sync_pub.publish(real_time_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    synchronizer = TimeSynchronizer()\n\n    try:\n        rclpy.spin(synchronizer)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        synchronizer.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"complete-integration-launch-file",children:"Complete Integration Launch File"}),"\n",(0,s.jsx)(n.p,{children:"Let's create a comprehensive launch file that brings all components together:"}),"\n",(0,s.jsx)(n.h3,{id:"python-launch-file",children:"Python Launch File"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription, RegisterEventHandler\nfrom launch.event_handlers import OnProcessStart\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import Command, LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\nfrom ament_index_python.packages import get_package_share_directory\nimport os\n\ndef generate_launch_description():\n    # Package names\n    pkg_share = FindPackageShare(\"my_robot_description\").find(\"my_robot_description\")\n    gazebo_pkg_share = FindPackageShare(\"gazebo_ros\").find(\"gazebo_ros\")\n\n    # Arguments\n    use_sim_time = LaunchConfiguration('use_sim_time', default='true')\n    is_simulation = LaunchConfiguration('is_simulation', default='true')\n\n    # Robot description\n    robot_description_content = Command([\n        'xacro ',\n        PathJoinSubstitution([pkg_share, 'urdf', 'my_robot.urdf.xacro'])\n    ])\n\n    # Robot state publisher\n    robot_state_publisher_node = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        name='robot_state_publisher',\n        parameters=[{\n            'use_sim_time': use_sim_time,\n            'robot_description': robot_description_content\n        }]\n    )\n\n    # Joint state publisher\n    joint_state_publisher_node = Node(\n        package='joint_state_publisher',\n        executable='joint_state_publisher',\n        name='joint_state_publisher',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    # Complete perception-action pipeline\n    perception_action_node = Node(\n        package='my_robot_control',\n        executable='complete_perception_action_pipeline',\n        name='complete_perception_action_pipeline',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/scan', '/scan'),\n            ('/camera/image_raw', '/camera/image_raw'),\n            ('/joint_states', '/joint_states'),\n            ('/imu/data', '/imu/data'),\n            ('/cmd_vel', '/cmd_vel'),\n        ]\n    )\n\n    # System validator\n    system_validator_node = Node(\n        package='my_robot_control',\n        executable='system_validator',\n        name='system_validator',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    # Hardware interface\n    hardware_interface_node = Node(\n        package='my_robot_control',\n        executable='hardware_interface',\n        name='hardware_interface',\n        parameters=[\n            {'use_sim_time': use_sim_time},\n            {'is_simulation': is_simulation}\n        ]\n    )\n\n    # Time synchronizer\n    time_synchronizer_node = Node(\n        package='my_robot_control',\n        executable='time_synchronizer',\n        name='time_synchronizer',\n        parameters=[{'use_sim_time': use_sim_time}]\n    )\n\n    # Gazebo launch (only if simulation)\n    gazebo_launch = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource(\n            os.path.join(gazebo_pkg_share, 'launch', 'gazebo.launch.py')\n        ),\n        condition=lambda context: LaunchConfiguration('is_simulation').perform(context) == 'true'\n    )\n\n    # Spawn robot in Gazebo\n    spawn_entity_node = Node(\n        package='gazebo_ros',\n        executable='spawn_entity.py',\n        arguments=[\n            '-topic', 'robot_description',\n            '-entity', 'my_robot',\n            '-x', '0', '-y', '0', '-z', '1.0'\n        ],\n        output='screen',\n        condition=lambda context: LaunchConfiguration('is_simulation').perform(context) == 'true'\n    )\n\n    return LaunchDescription([\n        DeclareLaunchArgument(\n            'use_sim_time',\n            default_value='true',\n            description='Use simulation time if true'\n        ),\n        DeclareLaunchArgument(\n            'is_simulation',\n            default_value='true',\n            description='Run in simulation mode if true'\n        ),\n        gazebo_launch,\n        robot_state_publisher_node,\n        joint_state_publisher_node,\n        spawn_entity_node,\n        perception_action_node,\n        system_validator_node,\n        hardware_interface_node,\n        time_synchronizer_node\n    ])\n"})}),"\n",(0,s.jsx)(n.h2,{id:"validation-and-testing-procedures",children:"Validation and Testing Procedures"}),"\n",(0,s.jsx)(n.h3,{id:"1-automated-validation-tests",children:"1. Automated Validation Tests"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import unittest\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import String\nfrom std_msgs.msg import Float64MultiArray\n\nclass TestCompleteSystemIntegration(unittest.TestCase):\n    def setUp(self):\n        rclpy.init()\n        self.node = Node(\'test_complete_system\')\n\n        # Create test publishers\n        self.cmd_vel_pub = self.node.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.joint_cmd_pub = self.node.create_publisher(Float64MultiArray, \'/joint_commands\', 10)\n\n        # Create test subscribers\n        self.status_sub = self.node.create_subscription(String, \'/system_status\', self.status_callback, 10)\n        self.joint_state_sub = self.node.create_subscription(JointState, \'/joint_states\', self.joint_state_callback, 10)\n\n        self.status_received = False\n        self.joint_state_received = False\n\n    def tearDown(self):\n        self.node.destroy_node()\n        rclpy.shutdown()\n\n    def status_callback(self, msg):\n        self.status_received = True\n\n    def joint_state_callback(self, msg):\n        self.joint_state_received = True\n\n    def test_system_responds_to_commands(self):\n        """Test that the system responds to velocity commands"""\n        cmd = Twist()\n        cmd.linear.x = 0.5\n        cmd.angular.z = 0.2\n\n        # Publish command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Wait for response\n        timeout = 0\n        while not self.status_received and timeout < 100:  # 10 seconds\n            rclpy.spin_once(self.node, timeout_sec=0.1)\n            timeout += 1\n\n        self.assertTrue(self.status_received, "System did not respond to velocity command")\n\n    def test_joint_state_updates(self):\n        """Test that joint states are being published"""\n        timeout = 0\n        while not self.joint_state_received and timeout < 100:  # 10 seconds\n            rclpy.spin_once(self.node, timeout_sec=0.1)\n            timeout += 1\n\n        self.assertTrue(self.joint_state_received, "Joint states not received")\n\nif __name__ == \'__main__\':\n    unittest.main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"step-by-step-integration-exercise",children:"Step-by-Step Integration Exercise"}),"\n",(0,s.jsx)(n.p,{children:"Follow these steps to integrate and validate your complete system:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Launch the complete system"})," using the integrated launch file"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Monitor system status"})," through the status topics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Send test commands"})," to verify the perception-action pipeline works"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Run validation tests"})," to ensure all components are functioning"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Test hardware abstraction"})," by switching between simulation and real hardware modes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Validate time synchronization"})," between real and simulation environments"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(n.p,{children:"In this lesson, you learned:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"How to implement complete perception-to-action pipelines for elementary tasks"}),"\n",(0,s.jsx)(n.li,{children:"How to perform end-to-end system validation"}),"\n",(0,s.jsx)(n.li,{children:"How to create complete integrated systems with validation tests"}),"\n",(0,s.jsx)(n.li,{children:"How to validate simulation compatibility with real hardware interfaces"}),"\n",(0,s.jsx)(n.li,{children:"How to implement time synchronization between real and simulation time"}),"\n",(0,s.jsx)(n.li,{children:"How to create hardware abstraction layers for simulation compatibility"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:'This completes Module 1 of the Physical AI & Humanoid Robotics course. You now have a complete understanding of how to create a "robotic nervous system" using ROS2, from basic communication patterns through complete AI integration and simulation readiness.'}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(n.p,{children:"With Module 1 complete, you're now ready to advance to Module 2, where you'll explore more advanced AI integration, vision-language-action systems, and complex decision-making algorithms that build upon the foundation you've established here."})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(m,{...e})}):m(e)}}}]);