"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[8725],{3281:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-1/python-ros2-integration-rclpy/lesson-4.2-simulation-environment-setup","title":"Lesson 4.2 - Simulation Environment Setup","description":"Learning Objectives","source":"@site/docs/module-1/4-python-ros2-integration-rclpy/lesson-4.2-simulation-environment-setup.md","sourceDirName":"module-1/4-python-ros2-integration-rclpy","slug":"/module-1/python-ros2-integration-rclpy/lesson-4.2-simulation-environment-setup","permalink":"/Physical_AI_Humanoid_Robotics_Book_With_RAG_Chatbot/docs/module-1/python-ros2-integration-rclpy/lesson-4.2-simulation-environment-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/AmanNazim/Physical_AI_Humanoid_Robotics_Book_With_RAG_Chatbot/edit/main/physical-ai-humanoid-robotics-book/docs/module-1/4-python-ros2-integration-rclpy/lesson-4.2-simulation-environment-setup.md","tags":[],"version":"current","frontMatter":{"title":"Lesson 4.2 - Simulation Environment Setup"},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 4.1 - Python-based ROS2 Nodes with rclpy","permalink":"/Physical_AI_Humanoid_Robotics_Book_With_RAG_Chatbot/docs/module-1/python-ros2-integration-rclpy/lesson-4.1-python-ros2-integration-with-rclpy"},"next":{"title":"Lesson 4.3 - Complete System Integration","permalink":"/Physical_AI_Humanoid_Robotics_Book_With_RAG_Chatbot/docs/module-1/python-ros2-integration-rclpy/lesson-4.3-complete-system-integration"}}');var t=o(4848),s=o(8453);const r={title:"Lesson 4.2 - Simulation Environment Setup"},a="Lesson 4.2 \u2013 Simulation Environment Setup",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Concept Overview and Scope",id:"concept-overview-and-scope",level:2},{value:"Understanding Gazebo and ROS2 Integration",id:"understanding-gazebo-and-ros2-integration",level:2},{value:"Key Components of Gazebo-ROS2 Integration:",id:"key-components-of-gazebo-ros2-integration",level:3},{value:"Setting Up Gazebo with Your Robot Model",id:"setting-up-gazebo-with-your-robot-model",level:2},{value:"1. Adding Gazebo-Specific Tags to URDF",id:"1-adding-gazebo-specific-tags-to-urdf",level:3},{value:"2. Controller Configuration",id:"2-controller-configuration",level:3},{value:"Launching Gazebo with Your Robot",id:"launching-gazebo-with-your-robot",level:2},{value:"Python Launch File",id:"python-launch-file",level:3},{value:"XML Launch File",id:"xml-launch-file",level:3},{value:"Interface Python Nodes with Gazebo Simulation",id:"interface-python-nodes-with-gazebo-simulation",level:2},{value:"1. Basic Simulation Controller Node",id:"1-basic-simulation-controller-node",level:3},{value:"2. Perception Processing Node for Simulation",id:"2-perception-processing-node-for-simulation",level:3},{value:"Building Perception-to-Action Pipelines",id:"building-perception-to-action-pipelines",level:2},{value:"Complete Pipeline Example",id:"complete-pipeline-example",level:3},{value:"Validation Techniques for Simulation",id:"validation-techniques-for-simulation",level:2},{value:"1. Sensor Data Validation",id:"1-sensor-data-validation",level:3},{value:"2. Control Command Validation",id:"2-control-command-validation",level:3},{value:"Common Simulation Issues and Solutions",id:"common-simulation-issues-and-solutions",level:2},{value:"Issue 1: Robot Falls Through Ground",id:"issue-1-robot-falls-through-ground",level:3},{value:"Issue 2: Joint Commands Not Working",id:"issue-2-joint-commands-not-working",level:3},{value:"Issue 3: Sensor Data Not Publishing",id:"issue-3-sensor-data-not-publishing",level:3},{value:"Issue 4: High CPU Usage",id:"issue-4-high-cpu-usage",level:3},{value:"Step-by-Step Exercise",id:"step-by-step-exercise",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"lesson-42--simulation-environment-setup",children:"Lesson 4.2 \u2013 Simulation Environment Setup"})}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Interface Python nodes with Gazebo simulation controllers"}),"\n",(0,t.jsx)(e.li,{children:"Build perception-to-action pipelines that work in simulation"}),"\n",(0,t.jsx)(e.li,{children:"Test simulation in Gazebo environment"}),"\n",(0,t.jsx)(e.li,{children:"Validate simulation-ready configurations"}),"\n",(0,t.jsx)(e.li,{children:"Configure robots for basic simulation in Gazebo or similar environments"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"concept-overview-and-scope",children:"Concept Overview and Scope"}),"\n",(0,t.jsx)(e.p,{children:"This lesson focuses on setting up and configuring simulation environments for humanoid robots using Gazebo, a powerful 3D simulation environment that provides accurate physics simulation, high-quality graphics, and convenient programmatic interfaces. We'll learn how to connect our Python-based AI agents to the simulated robot, enabling testing and validation of our perception-to-action pipelines in a safe, repeatable environment."}),"\n",(0,t.jsx)(e.p,{children:"Simulation is crucial for robotics development as it allows us to test complex behaviors without risk of hardware damage, enables faster iteration cycles, and provides controlled environments for debugging."}),"\n",(0,t.jsx)(e.h2,{id:"understanding-gazebo-and-ros2-integration",children:"Understanding Gazebo and ROS2 Integration"}),"\n",(0,t.jsx)(e.p,{children:"Gazebo provides a realistic physics simulation environment that can be integrated with ROS2 through the Gazebo ROS packages. The integration works through:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Gazebo Plugins"}),": These provide ROS2 interfaces to simulated sensors and actuators"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ROS2 Control"}),": For commanding simulated joints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"TF Transforms"}),": For robot state visualization"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor Simulation"}),": For realistic sensor data generation"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"key-components-of-gazebo-ros2-integration",children:"Key Components of Gazebo-ROS2 Integration:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"gazebo_ros_pkgs"}),": Provides the bridge between Gazebo and ROS2"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ros_gz"}),": Modern bridge for Gazebo Garden/Harmonic"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Controller Manager"}),": Manages robot controllers in simulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Robot State Publisher"}),": Publishes robot state for visualization"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"setting-up-gazebo-with-your-robot-model",children:"Setting Up Gazebo with Your Robot Model"}),"\n",(0,t.jsx)(e.p,{children:"To simulate your robot in Gazebo, you need to ensure your URDF model is properly configured for simulation. Here are the key elements:"}),"\n",(0,t.jsx)(e.h3,{id:"1-adding-gazebo-specific-tags-to-urdf",children:"1. Adding Gazebo-Specific Tags to URDF"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="my_robot">\n\n  \x3c!-- Include the robot\'s physical description --\x3e\n  <xacro:include filename="my_robot.urdf.xacro"/>\n\n  \x3c!-- Gazebo plugin for ROS control --\x3e\n  <gazebo>\n    <plugin name="gazebo_ros_control" filename="libgazebo_ros2_control.so">\n      <parameters>$(find my_robot_description)/config/my_robot_controllers.yaml</parameters>\n    </plugin>\n  </gazebo>\n\n  \x3c!-- Gazebo material definitions --\x3e\n  <gazebo reference="base_link">\n    <material>Gazebo/Blue</material>\n  </gazebo>\n\n  \x3c!-- Sensor plugins --\x3e\n  <gazebo reference="camera_link">\n    <sensor type="camera" name="camera_sensor">\n      <update_rate>30</update_rate>\n      <camera name="head_camera">\n        <horizontal_fov>1.3962634</horizontal_fov>\n        <image>\n          <width>800</width>\n          <height>600</height>\n          <format>R8G8B8</format>\n        </image>\n        <clip>\n          <near>0.1</near>\n          <far>100</far>\n        </clip>\n      </camera>\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n        <frame_name>camera_optical_frame</frame_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n\n</robot>\n'})}),"\n",(0,t.jsx)(e.h3,{id:"2-controller-configuration",children:"2. Controller Configuration"}),"\n",(0,t.jsxs)(e.p,{children:["Create a controller configuration file (",(0,t.jsx)(e.code,{children:"config/my_robot_controllers.yaml"}),"):"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:"controller_manager:\n  ros__parameters:\n    update_rate: 100  # Hz\n\n    joint_state_broadcaster:\n      type: joint_state_broadcaster/JointStateBroadcaster\n\n    velocity_controller:\n      type: velocity_controllers/JointGroupVelocityController\n\n    position_controller:\n      type: position_controllers/JointGroupPositionController\n\nvelocity_controller:\n  ros__parameters:\n    joints:\n      - joint1\n      - joint2\n      - joint3\n\nposition_controller:\n  ros__parameters:\n    joints:\n      - joint1\n      - joint2\n      - joint3\n"})}),"\n",(0,t.jsx)(e.h2,{id:"launching-gazebo-with-your-robot",children:"Launching Gazebo with Your Robot"}),"\n",(0,t.jsx)(e.p,{children:"Create a launch file to start Gazebo with your robot:"}),"\n",(0,t.jsx)(e.h3,{id:"python-launch-file",children:"Python Launch File"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import Command, LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node\nfrom launch_ros.substitutions import FindPackageShare\nfrom ament_index_python.packages import get_package_share_directory\nimport os\n\ndef generate_launch_description():\n    # Package names\n    pkg_share = FindPackageShare(\"my_robot_description\").find(\"my_robot_description\")\n    gazebo_pkg_share = FindPackageShare(\"gazebo_ros\").find(\"gazebo_ros\")\n\n    # Arguments\n    use_sim_time = LaunchConfiguration('use_sim_time', default='true')\n\n    # Robot description\n    robot_description_content = Command([\n        'xacro ',\n        PathJoinSubstitution([pkg_share, 'urdf', 'my_robot.urdf.xacro'])\n    ])\n\n    # Robot state publisher\n    robot_state_publisher_node = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        name='robot_state_publisher',\n        parameters=[{\n            'use_sim_time': use_sim_time,\n            'robot_description': robot_description_content\n        }]\n    )\n\n    # Spawn entity in Gazebo\n    spawn_entity_node = Node(\n        package='gazebo_ros',\n        executable='spawn_entity.py',\n        arguments=[\n            '-topic', 'robot_description',\n            '-entity', 'my_robot',\n            '-x', '0', '-y', '0', '-z', '1.0'\n        ],\n        output='screen'\n    )\n\n    # Gazebo launch\n    gazebo_launch = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource(\n            os.path.join(gazebo_pkg_share, 'launch', 'gazebo.launch.py')\n        )\n    )\n\n    return LaunchDescription([\n        DeclareLaunchArgument(\n            'use_sim_time',\n            default_value='true',\n            description='Use simulation time if true'\n        ),\n        gazebo_launch,\n        robot_state_publisher_node,\n        spawn_entity_node\n    ])\n"})}),"\n",(0,t.jsx)(e.h3,{id:"xml-launch-file",children:"XML Launch File"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'<launch>\n  \x3c!-- Arguments --\x3e\n  <arg name="use_sim_time" default="true"/>\n  <arg name="world" default="empty"/>\n\n  \x3c!-- Start Gazebo --\x3e\n  <include file="$(find-pkg-share gazebo_ros)/launch/gazebo.launch.py">\n    <arg name="world" value="$(var world)"/>\n    <arg name="gui" value="true"/>\n  </include>\n\n  \x3c!-- Robot State Publisher --\x3e\n  <node pkg="robot_state_publisher" exec="robot_state_publisher" name="robot_state_publisher">\n    <param name="use_sim_time" value="$(var use_sim_time)"/>\n    <param name="robot_description" value="$(command \'xacro $(find-pkg-share my_robot_description)/urdf/my_robot.urdf.xacro\')"/>\n  </node>\n\n  \x3c!-- Spawn robot in Gazebo --\x3e\n  <node pkg="gazebo_ros" exec="spawn_entity.py" args="-topic robot_description -entity my_robot -x 0 -y 0 -z 1.0" name="spawn_entity" output="screen"/>\n\n  \x3c!-- Load controllers --\x3e\n  <node pkg="controller_manager" exec="ros2_control_node" name="ros2_control_node" output="both">\n    <param name="robot_description" value="$(command \'xacro $(find-pkg-share my_robot_description)/urdf/my_robot.urdf.xacro\')"/>\n    <param name="use_sim_time" value="$(var use_sim_time)"/>\n  </node>\n</launch>\n'})}),"\n",(0,t.jsx)(e.h2,{id:"interface-python-nodes-with-gazebo-simulation",children:"Interface Python Nodes with Gazebo Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Now let's create Python nodes that can interface with the Gazebo simulation:"}),"\n",(0,t.jsx)(e.h3,{id:"1-basic-simulation-controller-node",children:"1. Basic Simulation Controller Node"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import Float64MultiArray\nfrom sensor_msgs.msg import JointState\nfrom geometry_msgs.msg import Twist\nimport math\n\nclass SimulationControllerNode(Node):\n    def __init__(self):\n        super().__init__('simulation_controller')\n\n        # Publisher for joint commands\n        self.joint_cmd_publisher = self.create_publisher(\n            Float64MultiArray,\n            '/velocity_controller/commands',\n            10\n        )\n\n        # Subscription to joint states\n        self.joint_state_subscriber = self.create_subscription(\n            JointState,\n            'joint_states',\n            self.joint_state_callback,\n            10\n        )\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.01, self.control_loop)  # 100Hz\n\n        self.current_joint_positions = []\n        self.get_logger().info('Simulation Controller Node has been started')\n\n    def joint_state_callback(self, msg):\n        self.current_joint_positions = list(msg.position)\n\n    def control_loop(self):\n        # Example: Simple sinusoidal motion for demonstration\n        cmd_msg = Float64MultiArray()\n\n        # Calculate commands based on current time\n        t = self.get_clock().now().nanoseconds / 1e9\n\n        # Example: Move joints in a coordinated pattern\n        commands = []\n        for i in range(len(self.current_joint_positions)):\n            command = math.sin(t + i * 0.5) * 0.5  # Amplitude of 0.5 rad/s\n            commands.append(command)\n\n        cmd_msg.data = commands\n        self.joint_cmd_publisher.publish(cmd_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = SimulationControllerNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h3,{id:"2-perception-processing-node-for-simulation",children:"2. Perception Processing Node for Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Image\nfrom geometry_msgs.msg import Twist\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\nclass SimulationPerceptionNode(Node):\n    def __init__(self):\n        super().__init__('simulation_perception')\n\n        # Subscriptions\n        self.laser_sub = self.create_subscription(\n            LaserScan,\n            'scan',\n            self.laser_callback,\n            10\n        )\n\n        self.camera_sub = self.create_subscription(\n            Image,\n            'camera/image_raw',\n            self.camera_callback,\n            10\n        )\n\n        # Publisher for velocity commands\n        self.cmd_vel_pub = self.create_publisher(Twist, 'cmd_vel', 10)\n\n        # CV Bridge for image processing\n        self.cv_bridge = CvBridge()\n\n        self.latest_scan = None\n        self.latest_image = None\n\n        # Timer for processing loop\n        self.process_timer = self.create_timer(0.1, self.process_data)\n\n        self.get_logger().info('Simulation Perception Node has been started')\n\n    def laser_callback(self, msg):\n        self.latest_scan = msg\n\n    def camera_callback(self, msg):\n        try:\n            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, \"bgr8\")\n            self.latest_image = cv_image\n        except Exception as e:\n            self.get_logger().error(f'Error converting image: {e}')\n\n    def process_data(self):\n        if self.latest_scan is None:\n            return\n\n        # Simple obstacle avoidance based on laser scan\n        cmd = Twist()\n\n        # Get distances in front, left, and right sectors\n        scan_ranges = self.latest_scan.ranges\n        front_distances = scan_ranges[:len(scan_ranges)//8] + scan_ranges[-len(scan_ranges)//8:]\n        left_distances = scan_ranges[len(scan_ranges)*3//8:len(scan_ranges)*5//8]\n        right_distances = scan_ranges[len(scan_ranges)*5//8:len(scan_ranges)*7//8]\n\n        min_front = min(front_distances) if front_distances else float('inf')\n        min_left = min(left_distances) if left_distances else float('inf')\n        min_right = min(right_distances) if right_distances else float('inf')\n\n        # Simple navigation logic\n        if min_front < 0.8:  # Obstacle ahead\n            cmd.linear.x = 0.0\n            if min_left > min_right:\n                cmd.angular.z = 0.5  # Turn left\n            else:\n                cmd.angular.z = -0.5  # Turn right\n        else:\n            cmd.linear.x = 0.5  # Move forward\n\n        self.cmd_vel_pub.publish(cmd)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = SimulationPerceptionNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h2,{id:"building-perception-to-action-pipelines",children:"Building Perception-to-Action Pipelines"}),"\n",(0,t.jsx)(e.p,{children:"In simulation, we can build complete perception-to-action pipelines that mirror real-world behavior:"}),"\n",(0,t.jsx)(e.h3,{id:"complete-pipeline-example",children:"Complete Pipeline Example"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan, Image, JointState\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import String\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\nimport math\n\nclass PerceptionToActionPipeline(Node):\n    def __init__(self):\n        super().__init__(\'perception_to_action_pipeline\')\n\n        # Subscriptions for different sensor modalities\n        self.laser_sub = self.create_subscription(\n            LaserScan, \'scan\', self.laser_callback, 10)\n        self.camera_sub = self.create_subscription(\n            Image, \'camera/image_raw\', self.camera_callback, 10)\n        self.joint_sub = self.create_subscription(\n            JointState, \'joint_states\', self.joint_callback, 10)\n\n        # Publishers for different action modalities\n        self.cmd_vel_pub = self.create_publisher(Twist, \'cmd_vel\', 10)\n        self.behavior_status_pub = self.create_publisher(String, \'behavior_status\', 10)\n\n        # CV Bridge for image processing\n        self.cv_bridge = CvBridge()\n\n        # State variables\n        self.latest_scan = None\n        self.latest_image = None\n        self.latest_joints = None\n        self.current_behavior = "EXPLORING"\n\n        # Timer for main processing loop\n        self.pipeline_timer = self.create_timer(0.05, self.pipeline_loop)  # 20Hz\n\n        self.get_logger().info(\'Perception-to-Action Pipeline has been started\')\n\n    def laser_callback(self, msg):\n        self.latest_scan = msg\n\n    def camera_callback(self, msg):\n        try:\n            cv_image = self.cv_bridge.imgmsg_to_cv2(msg, "bgr8")\n            self.latest_image = cv_image\n        except Exception as e:\n            self.get_logger().error(f\'Error converting image: {e}\')\n\n    def joint_callback(self, msg):\n        self.latest_joints = msg\n\n    def pipeline_loop(self):\n        if self.latest_scan is None:\n            return\n\n        # Process sensor data to make decisions\n        behavior_command = self.make_decision()\n\n        # Execute the behavior\n        self.execute_behavior(behavior_command)\n\n    def make_decision(self):\n        """Process sensor data and make behavioral decisions"""\n        if self.latest_scan is None:\n            return {"linear": 0.0, "angular": 0.0, "behavior": "WAITING"}\n\n        # Analyze laser scan for obstacles\n        scan_ranges = self.latest_scan.ranges\n        front_distances = scan_ranges[:len(scan_ranges)//8] + scan_ranges[-len(scan_ranges)//8:]\n        min_front = min(front_distances) if front_distances else float(\'inf\')\n\n        # Analyze image for specific features (simplified)\n        if self.latest_image is not None:\n            # Example: Check for red objects in image\n            hsv = cv2.cvtColor(self.latest_image, cv2.COLOR_BGR2HSV)\n            red_mask = cv2.inRange(hsv, (0, 100, 100), (10, 255, 255))\n            red_pixels = cv2.countNonZero(red_mask)\n\n            if red_pixels > 1000:  # If significant red detected\n                self.current_behavior = "APPROACH_RED"\n                return {"linear": 0.3, "angular": 0.0, "behavior": "APPROACH_RED"}\n\n        # Standard obstacle avoidance\n        if min_front < 0.8:\n            self.current_behavior = "AVOIDING_OBSTACLE"\n            # Turn in the direction with more space\n            left_distances = scan_ranges[len(scan_ranges)*3//8:len(scan_ranges)*5//8]\n            right_distances = scan_ranges[len(scan_ranges)*5//8:len(scan_ranges)*7//8]\n            min_left = min(left_distances) if left_distances else float(\'inf\')\n            min_right = min(right_distances) if right_distances else float(\'inf\')\n\n            if min_left > min_right:\n                return {"linear": 0.0, "angular": 0.5, "behavior": "AVOIDING_OBSTACLE"}\n            else:\n                return {"linear": 0.0, "angular": -0.5, "behavior": "AVOIDING_OBSTACLE"}\n        else:\n            self.current_behavior = "EXPLORING"\n            return {"linear": 0.5, "angular": 0.0, "behavior": "EXPLORING"}\n\n    def execute_behavior(self, command):\n        """Execute the decided behavior"""\n        cmd = Twist()\n        cmd.linear.x = command["linear"]\n        cmd.angular.z = command["angular"]\n\n        self.cmd_vel_pub.publish(cmd)\n\n        # Publish behavior status\n        status_msg = String()\n        status_msg.data = command["behavior"]\n        self.behavior_status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = PerceptionToActionPipeline()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"validation-techniques-for-simulation",children:"Validation Techniques for Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Proper validation ensures your robot behaves correctly in simulation:"}),"\n",(0,t.jsx)(e.h3,{id:"1-sensor-data-validation",children:"1. Sensor Data Validation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def validate_sensor_data(self, sensor_msg):\n    """Validate that sensor data is reasonable"""\n    if sensor_msg is None:\n        return False\n\n    # Check for NaN or infinite values\n    if hasattr(sensor_msg, \'ranges\'):\n        for range_val in sensor_msg.ranges:\n            if math.isnan(range_val) or math.isinf(range_val):\n                self.get_logger().warning(f\'Invalid range value: {range_val}\')\n                return False\n\n    return True\n'})}),"\n",(0,t.jsx)(e.h3,{id:"2-control-command-validation",children:"2. Control Command Validation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def validate_control_command(self, cmd):\n    """Validate control commands before sending to robot"""\n    if abs(cmd.linear.x) > self.max_linear_velocity:\n        cmd.linear.x = math.copysign(self.max_linear_velocity, cmd.linear.x)\n        self.get_logger().warning(f\'Linear velocity clamped to {self.max_linear_velocity}\')\n\n    if abs(cmd.angular.z) > self.max_angular_velocity:\n        cmd.angular.z = math.copysign(self.max_angular_velocity, cmd.angular.z)\n        self.get_logger().warning(f\'Angular velocity clamped to {self.max_angular_velocity}\')\n\n    return cmd\n'})}),"\n",(0,t.jsx)(e.h2,{id:"common-simulation-issues-and-solutions",children:"Common Simulation Issues and Solutions"}),"\n",(0,t.jsx)(e.h3,{id:"issue-1-robot-falls-through-ground",children:"Issue 1: Robot Falls Through Ground"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Symptoms"}),": Robot falls through the ground or other static objects\n",(0,t.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Check that collision geometries are properly defined"}),"\n",(0,t.jsx)(e.li,{children:"Verify that the robot has proper mass and inertia properties"}),"\n",(0,t.jsx)(e.li,{children:"Ensure physics parameters are set correctly in Gazebo"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"issue-2-joint-commands-not-working",children:"Issue 2: Joint Commands Not Working"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Symptoms"}),": Joint commands sent to the robot have no effect\n",(0,t.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Verify controller configuration files are correct"}),"\n",(0,t.jsx)(e.li,{children:"Check that controller manager is running"}),"\n",(0,t.jsx)(e.li,{children:"Ensure proper topic names and message types"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"issue-3-sensor-data-not-publishing",children:"Issue 3: Sensor Data Not Publishing"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Symptoms"}),": Sensor topics are not publishing data\n",(0,t.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Check Gazebo sensor plugin configuration"}),"\n",(0,t.jsx)(e.li,{children:"Verify that sensors are properly attached to links"}),"\n",(0,t.jsx)(e.li,{children:"Confirm that physics simulation is running"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"issue-4-high-cpu-usage",children:"Issue 4: High CPU Usage"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Symptoms"}),": Simulation runs slowly or uses excessive CPU\n",(0,t.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Reduce physics update rate in Gazebo"}),"\n",(0,t.jsx)(e.li,{children:"Simplify collision geometries"}),"\n",(0,t.jsx)(e.li,{children:"Limit the number of sensors in simulation"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"step-by-step-exercise",children:"Step-by-Step Exercise"}),"\n",(0,t.jsx)(e.p,{children:"Create a complete simulation setup for your robot:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Add Gazebo plugins to your URDF file"}),"\n",(0,t.jsx)(e.li,{children:"Create a controller configuration file"}),"\n",(0,t.jsx)(e.li,{children:"Create a launch file to start Gazebo with your robot"}),"\n",(0,t.jsx)(e.li,{children:"Implement a Python node that controls your simulated robot"}),"\n",(0,t.jsx)(e.li,{children:"Test the simulation and validate the behavior"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"In this lesson, you learned:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"How to configure your robot model for Gazebo simulation"}),"\n",(0,t.jsx)(e.li,{children:"How to interface Python nodes with Gazebo simulation controllers"}),"\n",(0,t.jsx)(e.li,{children:"How to build perception-to-action pipelines that work in simulation"}),"\n",(0,t.jsx)(e.li,{children:"How to validate simulation-ready configurations"}),"\n",(0,t.jsx)(e.li,{children:"Common issues and solutions in robot simulation"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Simulation provides a safe, repeatable environment for testing and validating your robot's behavior before deploying to real hardware."}),"\n",(0,t.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(e.p,{children:"In the final lesson of this module, we'll integrate all components into a complete system and perform end-to-end validation of our perception-to-action pipeline in both simulation and preparation for real hardware."})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,o)=>{o.d(e,{R:()=>r,x:()=>a});var i=o(6540);const t={},s=i.createContext(t);function r(n){const e=i.useContext(s);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:r(n.components),i.createElement(s.Provider,{value:e},n.children)}}}]);