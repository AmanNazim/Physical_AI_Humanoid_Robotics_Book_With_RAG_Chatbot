# Database Subsystem for Global RAG Chatbot System

## Overview

The Database Subsystem serves as the foundational data management layer of the Global RAG Chatbot System. It consists of two specialized database technologies:

1. **Qdrant** - For vector storage and retrieval of embeddings
2. **Neon/PostgreSQL** - For structured data persistence

This subsystem provides the essential infrastructure for storing, indexing, and retrieving all system data while maintaining strict separation of concerns between vector and structured data.

## Architecture

### Qdrant Vector Database
- Stores 1024-dimensional vector embeddings generated by Cohere API
- Enables fast cosine similarity search with configurable parameters
- Supports metadata filtering during vector search operations
- Maintains payload schema with chunk_id, text_content, document_reference, and metadata fields

### Neon/PostgreSQL Structured Database
- Stores all non-vector data including metadata, logs, chat history, and system configuration
- Maintains ACID transactional guarantees
- Supports complex queries with JOIN operations across related tables
- Implements proper indexing strategies for query performance

## Components

### Qdrant Components
- `qdrant_client.py` - Qdrant client wrapper with robust retry logic
- `qdrant_collection_manager.py` - Manages Qdrant collection operations
- `qdrant_schema.py` - Defines schema for Qdrant payload structure
- `qdrant_utils.py` - Utility functions for Qdrant data structures

### PostgreSQL Components
- `pg_client.py` - Async PostgreSQL client with connection pooling
- `pg_schema.sql` - SQL schema definitions for all tables
- `pg_queries.py` - Prepared SQL statements for all operations
- `pg_models.py` - Pydantic models for database entities
- `pg_utils.py` - Utility functions for PostgreSQL operations

### Database Abstraction Layer
- `database_manager.py` - Unified access to both databases implementing DatabaseInterface
- `config_loader.py` - Configuration loader for database settings

## Installation & Setup

### Prerequisites
- Python 3.10+
- Qdrant Cloud account (for vector database)
- Neon Serverless Postgres account (for structured data)

### Environment Configuration
Create a `.env` file with the following variables:
```env
QDRANT_HOST=https://your-qdrant-instance.qdrant.tech
QDRANT_API_KEY=your-qdrant-api-key
QDRANT_COLLECTION_NAME=book_embeddings

NEON_DATABASE_URL=postgresql://username:password@ep-xxx.us-east-1.aws.neon.tech/dbname
NEON_POOL_SIZE=10
NEON_POOL_TIMEOUT=30
```

### Dependencies
```bash
uv pip install qdrant-client asyncpg python-dotenv pydantic-settings
```

## Usage

### Initialize the Database Manager
```python
from databases.database_manager import initialize_database_manager

# Initialize the database manager
db_manager = await initialize_database_manager()

# Or use as an async context manager
from databases.database_manager import get_database_manager

async with get_database_manager() as db:
    # Perform database operations
    success = await db.store_chunk_metadata(chunk_metadata)
```

### Storing Embeddings
```python
# Store an embedding in Qdrant with metadata in PostgreSQL
success = await db_manager.store_embedding(
    chunk_id="unique-chunk-id",
    vector=[0.1, 0.2, 0.3, ...],  # 1024-dimensional vector
    text="Sample chunk text",
    document_reference="document-ref-123",
    metadata={"source": "book", "page": 10}
)
```

### Querying Embeddings
```python
# Query similar embeddings from Qdrant
results = await db_manager.query_embeddings(
    query_vector=[0.1, 0.2, 0.3, ...],  # 1024-dimensional query vector
    top_k=5,
    filters={"document_reference": "document-ref-123"}
)
```

### Storing and Retrieving Chunk Metadata
```python
from databases.postgres.pg_models import ChunkMetadata

# Store chunk metadata
chunk = ChunkMetadata(
    chunk_id="unique-id",
    document_reference="doc-ref",
    chunk_text="Sample text content",
    embedding_id="embedding-id",
    processing_version="1.0"
)

success = await db_manager.store_chunk_metadata(chunk)

# Retrieve chunk metadata
retrieved_chunk = await db_manager.get_chunk_metadata("unique-id")
```

### Managing Chat History
```python
from databases.postgres.pg_models import ChatHistoryEntry

# Store chat history
chat_entry = ChatHistoryEntry(
    chat_id="chat-session-id",
    user_id="user-id",
    query="User question",
    response="AI response",
    source_chunks=[{"id": "chunk-1", "text": "relevant text"}],
    timestamp="2023-12-23T10:00:00Z"
)

success = await db_manager.store_chat_history(chat_entry)

# Retrieve chat history
history = await db_manager.get_chat_history(user_id="user-id", limit=10)
```

## Testing

### Qdrant Tests
- Test vector storage and retrieval with sample embeddings
- Verify metadata payload structure
- Validate similarity search performance (<500ms)

### PostgreSQL Tests
- Test CRUD operations on all tables
- Verify foreign key relationships
- Validate query performance (<100ms for single record lookup)

### Integration Tests
- Test cross-database consistency
- Verify ID mapping between systems
- Validate error handling for cross-database queries

## Performance Benchmarks

- **Vector similarity search**: <500ms for top-5 results
- **Metadata retrieval**: <100ms for single record lookup
- **Batch operations**: <2 seconds for standard batch sizes
- **Cross-database consistency checks**: <1 second

## Security Considerations

- All data transmission encrypted in transit
- API keys stored securely and rotated regularly
- Access control and authentication for all database connections
- Audit logging for all data access and modification operations
- Principle of least privilege for system components

## Troubleshooting

### Common Issues
1. **Connection failures**: Verify API keys and database URLs in environment variables
2. **Performance issues**: Check indexing strategies and connection pooling settings
3. **Cross-database inconsistency**: Run consistency validation functions

### Health Checks
- Qdrant: Verify collection exists and is accessible
- PostgreSQL: Test connection and run basic SELECT query
- Overall: Validate cross-database consistency

## Deployment

### Production Configuration
- Use production-grade Qdrant Cloud and Neon Serverless instances
- Configure appropriate connection pooling and timeouts
- Set up monitoring and alerting for database performance
- Implement backup procedures for PostgreSQL

### Monitoring
- Query response times
- Database connection pool metrics
- Storage capacity utilization
- Error rates and slow query detection

## Future Extensions

- Multi-vector embeddings support
- Semantic caching layer
- Vector re-ranking database
- Multi-tenant data isolation
- Hybrid search capabilities
- Distributed architecture with sharding